{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "4-_I1lfk27Qk"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2DBrrIQMP6Fh"
   },
   "source": [
    "# **Node**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t06qM3Y38gm6"
   },
   "source": [
    "The Node class greates the graph node. It has the following values\n",
    "\n",
    "1. Parent Node\n",
    "2. State\n",
    "3. Cost\n",
    "\n",
    "It makes use of the following built in functions:\n",
    "\n",
    "1. __hash__ : This provides the hash value for every node, which is required for the hashset\n",
    "2. __eq__ : To check if 2 nodes are equal (Operator overload)\n",
    "3. __ne__ : To check if 2 nodes are not equal (Operator overload)\n",
    "4. __str__ : To get string representation of state in node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hzCAX4vA3tHj"
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, parent, state, pcost, hcost, action=None):\n",
    "        \n",
    "        self.parent = parent\n",
    "        self.state = state\n",
    "        self.action = action\n",
    "        self.pcost = pcost\n",
    "        self.hcost = hcost\n",
    "        self.cost = pcost + hcost\n",
    "    \n",
    "    def __hash__(self):\n",
    "        \n",
    "        return hash(str(self.state.flatten()))\n",
    "    \n",
    "    def __str__(self):\n",
    "        return str(self.state)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        \n",
    "        return hash(''.join(self.state.flatten())) == hash(''.join(other.state.flatten())) \n",
    "    \n",
    "    def __ne__(self, other):\n",
    "        return hash(''.join(self.state.flatten())) != hash(''.join(other.state.flatten()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t7X1h7eK4Gv7"
   },
   "source": [
    "# **Priority Queue**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4x5TzH187Z-"
   },
   "source": [
    "The Priority Queue is used to store the nodes along with the cost, and pop the node having the least cost for BFS\n",
    "\n",
    "It makes use of the following functions:\n",
    "\n",
    "1. push : Add node to queue\n",
    "2. pop : Pop node having least cost\n",
    "3. is_empty : To check if queue is empty\n",
    "4. __len__ : To get length of queue\n",
    "5. __str__ : To get string representation of queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VRNprFAW4uKj"
   },
   "outputs": [],
   "source": [
    "class PriorityQueue():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.queue = []\n",
    "        self.hashes = {}\n",
    "        \n",
    "    def push(self, node):\n",
    "        if hash(node) not in self.hashes:\n",
    "            self.hashes[hash(node)] = 1\n",
    "            self.queue.append(node)\n",
    "    \n",
    "    def pop(self):\n",
    "        \n",
    "        next_state = None\n",
    "        state_cost = 10**18\n",
    "        index = -1\n",
    "        \n",
    "        for i in range(len(self.queue)):\n",
    "            \n",
    "            if self.queue[i].cost<state_cost:\n",
    "                state_cost = self.queue[i].cost\n",
    "                index = i\n",
    "        \n",
    "        return self.queue.pop(index)\n",
    "    \n",
    "    def is_empty(self):\n",
    "        \n",
    "        return len(self.queue)==0\n",
    "    \n",
    "    def __str__(self):\n",
    "        l = []\n",
    "        for i in self.queue:\n",
    "            l.append(i.state)\n",
    "        \n",
    "        return str(l)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.queue)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TyS0YxSx40Ii"
   },
   "source": [
    "# **Environment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4e4PSRA9Jfy"
   },
   "source": [
    "The environment is what the agent plays in. It has the following entities:\n",
    "\n",
    "1. actions : The actions defined in the environment\n",
    "2. depth: the maximum depth of the solution\n",
    "3. goal_state : The goal state of the environment\n",
    "4. start_state : The start state generated at the depth\n",
    "\n",
    "It has the following functions:\n",
    "\n",
    "1. get_start_state : returns the start state\n",
    "2. reached_goal : returns goal_state\n",
    "3. get_next_states : Given current state, it returns all possible next states\n",
    "4. generate_start_state : Given goal state and depth d, performs d moves to generate a start state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8NxviUMQ46xq"
   },
   "outputs": [],
   "source": [
    "class Environment():\n",
    "    \n",
    "    def __init__(self, start_state=None, goal_state=None):\n",
    "        self.actions = [1,2,3,4] #1 - Up, 2 - Down, 3 - Right, 4 - Left\n",
    "        if goal_state is None:\n",
    "            self.goal_state = self.generate_goal_state()\n",
    "        else:\n",
    "            self.goal_state = goal_state\n",
    "        if start_state is None:\n",
    "            self.start_state = self.generate_start_state()\n",
    "        else:\n",
    "            self.start_state = start_state\n",
    "    \n",
    "    def generate_start_state(self):\n",
    "        \n",
    "        start = np.zeros((7,7))\n",
    "        x = (0,1,5,6)\n",
    "        y = (0,1,5,6)\n",
    "\n",
    "        for i in x:\n",
    "            for j in y:\n",
    "                start[i][j] = -1;\n",
    "\n",
    "        x = (2,3,4)\n",
    "        y = range(7)\n",
    "\n",
    "        for i in x:\n",
    "            for j in y:\n",
    "                start[i][j] = 1\n",
    "                start[j][i] = 1\n",
    "        start[3][3] = 0\n",
    "        \n",
    "        return start\n",
    "    \n",
    "    def generate_goal_state(self):\n",
    "    \n",
    "        goal = np.zeros((7,7))\n",
    "        x = (0,1,5,6)\n",
    "        y = (0,1,5,6)\n",
    "\n",
    "        for i in x:\n",
    "            for j in y:\n",
    "                goal[i][j] = -1;\n",
    "\n",
    "        x = (2,3,4)\n",
    "        y = range(7)\n",
    "\n",
    "        for i in x:\n",
    "            for j in y:\n",
    "                goal[i][j] = 0\n",
    "                goal[j][i] = 0\n",
    "        goal[3][3] = 1\n",
    "        return goal\n",
    "\n",
    "    def get_start_state(self):\n",
    "        return self.start_state\n",
    "    \n",
    "    def get_goal_state(self):\n",
    "        return self.goal_state\n",
    "    \n",
    "    def get_next_states(self, state):\n",
    "        \n",
    "        new_states = []\n",
    "        spaces = []\n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "                if state[i][j]==0:\n",
    "                    spaces.append((i,j))\n",
    "        \n",
    "        for space in spaces:\n",
    "            \n",
    "            x, y = space\n",
    "            #Move from top to bottom\n",
    "            if x>1:\n",
    "                if state[x-1][y]==1 and state[x-2][y]==1:\n",
    "                    new_state = state.copy()\n",
    "                    new_state[x][y] = 1\n",
    "                    new_state[x-2][y] = 0\n",
    "                    new_state[x-1][y] = 0\n",
    "                    action = f'({x-2}, {y}) -> ({x}, {y})'\n",
    "                    new_states.append((new_state, action))\n",
    "            #Move from bottom to top\n",
    "            if x<5:\n",
    "                if state[x+1][y]==1 and state[x+2][y]==1:\n",
    "                    new_state = state.copy()\n",
    "                    new_state[x][y] = 1\n",
    "                    new_state[x+2][y] = 0\n",
    "                    new_state[x+1][y] = 0\n",
    "                    action = f'({x+2}, {y}) -> ({x}, {y})'\n",
    "                    new_states.append((new_state, action))\n",
    "            \n",
    "            #Move from left to right\n",
    "            if y>1:\n",
    "                if state[x][y-1]==1 and state[x][y-2]==1:\n",
    "                    new_state = state.copy()\n",
    "                    new_state[x][y] = 1\n",
    "                    new_state[x][y-2] = 0\n",
    "                    new_state[x][y-1] = 0\n",
    "                    action = f'({x}, {y-2}) -> ({x}, {y})'\n",
    "                    new_states.append((new_state, action))\n",
    "            \n",
    "            if y<5:\n",
    "                if state[x][y+1]==1 and state[x][y+2]==1:\n",
    "                    new_state = state.copy()\n",
    "                    new_state[x][y] = 1\n",
    "                    new_state[x][y+2] = 0\n",
    "                    new_state[x][y+1] = 0\n",
    "                    action = f'({x}, {y+2}) -> ({x}, {y})'\n",
    "                    new_states.append((new_state, action))\n",
    "        \n",
    "        return new_states\n",
    "    \n",
    "    def reached_goal(self, state):\n",
    "        \n",
    "        for i in range(7):\n",
    "            for j in range(7):\n",
    "                if state[i,j] != self.goal_state[i,j]:\n",
    "                    return False\n",
    "                    \n",
    "        \n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGLOwkZg9xgE"
   },
   "source": [
    "\n",
    "# **Agent**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hGyQhDpu96D9"
   },
   "source": [
    "The agent is the player who plays the game against the environment to win. It has the following entities:\n",
    "\n",
    "1. frontier : This is the priority queue used to store the nodes to be explored.\n",
    "2. explored : This is the dictionary which stores the explored nodes\n",
    "3. start_state : Stores the start state\n",
    "4. goal_state : Stores the goal state\n",
    "5. env : Stores the environment\n",
    "6. goal_node : Stores the goal node if found\n",
    "7. heuristic : Stores the heuristic function\n",
    "\n",
    "The agent has the following functions:\n",
    "\n",
    "1. run(): Is the function that explores the environment and finds the goal node. Uses the built in heuristic function to get the path costs\n",
    "2. print_nodes(): To print the path from the start node to goal node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GTgb8Fr_5IKu"
   },
   "outputs": [],
   "source": [
    "class Agent1:\n",
    "    \n",
    "    def __init__(self, env, heuristic):\n",
    "        self.frontier = PriorityQueue()\n",
    "        self.explored = dict()\n",
    "        self.start_state = env.get_start_state()\n",
    "        self.goal_state = env.get_goal_state()\n",
    "        self.env = env\n",
    "        self.goal_node = None\n",
    "        self.heuristic = heuristic\n",
    "    \n",
    "    def run(self):\n",
    "        init_node = Node(parent = None, state = self.start_state, pcost = 0, hcost = 0)\n",
    "        self.frontier.push(init_node)\n",
    "        start = time()\n",
    "        while not self.frontier.is_empty():\n",
    "\n",
    "            curr_node = self.frontier.pop()\n",
    "            next_states = self.env.get_next_states(curr_node.state)\n",
    "\n",
    "            if hash(curr_node) in self.explored:\n",
    "                continue\n",
    "                \n",
    "            self.explored[hash(curr_node)] = curr_node\n",
    "\n",
    "            if self.env.reached_goal(curr_node.state):\n",
    "                print(\"Reached goal!\")\n",
    "                self.goal_node = curr_node\n",
    "                break\n",
    "            goal_state = self.env.get_goal_state()\n",
    "\n",
    "            l = []\n",
    "            for state in next_states:\n",
    "\n",
    "                hcost = self.heuristic(state[0])\n",
    "                node = Node(parent=curr_node, state=state[0], pcost=curr_node.pcost+1, hcost=hcost, action=state[1])\n",
    "                self.frontier.push(node)\n",
    "\n",
    "        end = time()\n",
    "        print(end - start)\n",
    "        return end-start\n",
    "    \n",
    "    def print_nodes(self):\n",
    "        \n",
    "        node = self.goal_node\n",
    "        l = []\n",
    "        while node is not None:\n",
    "            l.append(node)\n",
    "            node = node.parent\n",
    "\n",
    "        step = 1\n",
    "        for node in l[::-1]:\n",
    "            print(\"Step: \",step)\n",
    "            print(node.action)\n",
    "            #print(node)\n",
    "            step+=1\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dWyVi6PX9m6K"
   },
   "source": [
    "Using both heuristic cost and path cost\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eHVa85Wv5MfV"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# **Heuristic 0**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1DZGMiG1-L8j"
   },
   "source": [
    "This is a null heuristic, returns 0 for any state. Essentially uniform cost search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "JqFTYQFc5Vq7"
   },
   "outputs": [],
   "source": [
    "def heuristic0(curr_state):\n",
    "    return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zQV7ldWT5YCP"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# **Heuristic 1**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZlriWeTk-Rtv"
   },
   "source": [
    "This is the manhattan distance, it returns the sum of the horizontal and vertical distances of the all marble in current state from center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_KeAaaWo5bqn"
   },
   "outputs": [],
   "source": [
    "def heuristic1(curr_state):\n",
    "    cost = 0\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            if curr_state[i][j]==1:\n",
    "                cost += abs(i-3)+abs(j-3)\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VFG7t-Tk5fBu"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# **Heuristic 2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcYrocvr-Vf2"
   },
   "source": [
    "This is the exponential distance, it returns the 2<sup>max(H,V) </sup>, where H is the horizontal distance, and V is the vertical distance.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cXLwp68_5le0"
   },
   "outputs": [],
   "source": [
    "def heuristic2(curr_state):\n",
    "    cost = 0\n",
    "    for i in range(7):\n",
    "        for j in range(7):\n",
    "            if curr_state[i][j]==1:\n",
    "                cost += 2**(max(abs(i-3),abs(j-3)))\n",
    "    \n",
    "    return cost\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fRjRM0br5Csx"
   },
   "source": [
    "\n",
    "# **A-star Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r6lqdDOcOrc-",
    "outputId": "7e607899-96b6-4c10-900f-5a4cd482f29e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached goal!\n",
      "164.51601934432983\n",
      "Reached goal!\n",
      "153.14466333389282\n",
      "Reached goal!\n",
      "153.85625386238098\n",
      "Reached goal!\n",
      "155.1975975036621\n",
      "Reached goal!\n",
      "161.5449457168579\n",
      "Average time 157.65189595222472\n",
      "Number of nodes explored: 33353\n",
      "Number of nodes in frontier: 213\n"
     ]
    }
   ],
   "source": [
    "t = 0\n",
    "for i in range(5):\n",
    "    agent = Agent1(Environment(), heuristic2)\n",
    "    t+=agent.run()\n",
    "    \n",
    "print(\"Average time\", t/5)\n",
    "\n",
    "print(\"Number of nodes explored:\", len(agent.explored))\n",
    "print(\"Number of nodes in frontier:\", len(agent.frontier))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97Ew1vIq5xPj"
   },
   "source": [
    "# **Best First Search**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dccqG4VF_FYv"
   },
   "source": [
    "Using Only Heuristic (Heuristic 2 from above cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qBt07RrB50rE",
    "outputId": "ddb10329-bc8c-44ab-f129-be4c351e89da"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reached goal!\n",
      "175.90969848632812\n",
      "Reached goal!\n",
      "176.44451212882996\n",
      "Reached goal!\n",
      "171.4712610244751\n",
      "Reached goal!\n",
      "179.49963235855103\n",
      "Reached goal!\n",
      "179.8640739917755\n",
      "Average time 176.63783559799194\n",
      "Number of nodes explored: 35997\n",
      "Number of nodes in frontier: 133\n"
     ]
    }
   ],
   "source": [
    "class Agent2:\n",
    "    \n",
    "    def __init__(self, env, heuristic):\n",
    "        self.frontier = PriorityQueue()\n",
    "        self.explored = dict()\n",
    "        self.start_state = env.get_start_state()\n",
    "        self.goal_state = env.get_goal_state()\n",
    "        self.env = env\n",
    "        self.goal_node = None\n",
    "        self.heuristic = heuristic\n",
    "    \n",
    "    def run(self):\n",
    "        init_node = Node(parent = None, state = self.start_state, pcost = 0, hcost = 0)\n",
    "        self.frontier.push(init_node)\n",
    "        start = time()\n",
    "        while not self.frontier.is_empty():\n",
    "\n",
    "            curr_node = self.frontier.pop()\n",
    "            next_states = self.env.get_next_states(curr_node.state)\n",
    "\n",
    "            if hash(curr_node) in self.explored:\n",
    "                continue\n",
    "                \n",
    "            self.explored[hash(curr_node)] = curr_node\n",
    "\n",
    "            if self.env.reached_goal(curr_node.state):\n",
    "                print(\"Reached goal!\")\n",
    "                self.goal_node = curr_node\n",
    "                break\n",
    "            goal_state = self.env.get_goal_state()\n",
    "\n",
    "            l = []\n",
    "            for state in next_states:\n",
    "\n",
    "                hcost = self.heuristic(state[0])\n",
    "                node = Node(parent=curr_node, state=state[0], pcost=0, hcost=hcost, action=state[1])\n",
    "                self.frontier.push(node)\n",
    "        \n",
    "        end = time()\n",
    "        print(end - start)\n",
    "        return end-start\n",
    "    \n",
    "    def print_nodes(self):\n",
    "        \n",
    "        node = self.goal_node\n",
    "        l = []\n",
    "        while node is not None:\n",
    "            l.append(node)\n",
    "            node = node.parent\n",
    "\n",
    "        step = 1\n",
    "        for node in l[::-1]:\n",
    "            print(\"Step: \",step)\n",
    "            print(node.action)\n",
    "            #print(node)\n",
    "            step+=1\n",
    "\n",
    "t = 0\n",
    "for i in range(5):\n",
    "    agent = Agent2(Environment(), heuristic2)\n",
    "    t+=agent.run()\n",
    "    \n",
    "print(\"Average time\", t/5)\n",
    "print(\"Number of nodes explored:\", len(agent.explored))\n",
    "print(\"Number of nodes in frontier:\", len(agent.frontier))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
